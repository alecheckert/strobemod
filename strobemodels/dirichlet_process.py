#!/usr/bin/env python
"""
dirichlet_process.py -- use a Dirichlet process mixture model to 
estimate the posterior distribution of diffusivities given trajectories
sampled from a Brownian mixture.

Suppose we have *n* trajectories that are labeled i = 1, ..., n, and
that the summed 2D radial squared displacement of the i^th trajectory
is X[i], and that the diffusivity of trajectory is some D[i].

Then our model is

    X[i] | D[i] ~ Gamma(1, 1 / (4 * D[i] * dt))
    D[i] | G ~ G
    G ~ DP(alpha, H)

where dt is the frame interval, G is a candidate diffusivity
distribution drawn from the Dirichlet process DP(alpha, H), and 
H is the prior on that distribution. In most of the cases here,
we assume that H is a uniform distribution on the range of 
diffusivities of interest, unless otherwise specified.

Our goal is to evaluate the posterior distribution D | X, 
marginalizing on G. We do this using algorithm 8 from Neal 2000,
which is a hybrid Gibbs sampling/Metropolis scheme based on the
basic conditional/marginal likelihoods from the Blackwell-MacQueen
1973 urn model. See

        Radford M. Neal. Markov Chain Sampling Methods for Dirichlet
        Process Mixture Models. Journal of Computational and Graphical
        Statistics, 9:2, 249-265 (2000).

for more details.

"""
import os
import sys
import time
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt 
import dask 

from strobemodels.utils import defoc_prob_brownian, track_length
from strobemodels.specdiffuse import rad_disp_squared

def gs_dp_log_diff(tracks, diffusivity_bin_edges, alpha=10.0, m=10,
    m0=30, n_iter=1000, burnin=20, frame_interval=0.01,
    pixel_size_um=1.0, max_jumps_per_track=20, min_jumps_per_track=1,
    B=10000, metropolis_sigma=0.1):

    raise NotImplementedError

def gs_dp_log_diff_par(tracks, diffusivity_bin_edges, alpha=10.0, m=10,
    m0=30, n_iter=1000, burnin=20, frame_interval=0.01, pixel_size_um=1.0, 
    max_jumps_per_track=20, min_jumps_per_track=1, B=10000, 
    metropolis_sigma=0.1, num_workers=6, max_occ_weight=5, loc_error=0.0,
    dz=None):
    """
    Given a set of trajectories and a log-uniform prior, estimate the
    posterior distribution of diffusivities.

    Our Gibbs sampling algorithm to do this is based on algorithm 8 from 
    Radford Neal's paper:

        Radford M. Neal. Markov Chain Sampling Methods for Dirichlet Process
        Mixture Models. Journal of Computational and Graphical Statistics,
        9:2, 249-265 (2000).
    
    The idea is to specify the state of a Markov chain sampler as a set of 
    components generated by one draw of a Dirichlet process on the spectrum
    of possible diffusivities. Each component has an associated probability 
    and an associated diffusivity.

    For inference, our observations are trajectories that are assumed to have
    been produced by some component. If these observations are indexed by i
    so that observation i was produced by the component with diffusivity D[i],
    then our model can be written

        Y[i] | D[i] ~ Gamma(L[i], 1 / (4 * D[i] * t))
        D[i] | G ~ G 
        G ~ DP(alpha, prior)

    where Y[i] is the sum squared 2D radial displacement of the i^th 
    observation, L[i] is the number of displacements in trajectory i, 
    t is the frame interval, and DP(alpha, prior) is a Dirichlet process.

    Our prior in this case is taken to be a uniform distribution.

    important
    ---------
        This function relies on a compiled version of the C++ program 
        "gs_dp_diff" in PATH.

    args
    ----
        tracks                  :   pandas.DataFrame, trajectories

        diffusivity_bin_edges   :   1D ndarray of shape (n_bins+1,), the
                                    edges of each diffusivity bin in
                                    um^2 s^-1

        alpha                   :   float, the concentration parameter
                                    for the Dirichlet process

        m                       :   int, the number of auxiliary Markov
                                    chains to use at each step. The
                                    higher this number is, the better
                                    the sampling of the diffusivity 
                                    distribution conditional on some
                                    trajectories, but also the algorithm
                                    is slower.

        m0                      :   int, the number of Markov chains to
                                    start with

        n_iter                  :   int, the number of iterations to do

        burnin                  :   int, the number of iterations to do
                                    before recording any results

        frame_interval          :   float, time between frames in seconds

        pixel_size_um           :   float, the size of each pixel in um

        max_jumps_per_track     :   int, the maximum number of jumps to
                                    consider per track 

        min_jumps_per_track     :   int, the minimum number of jumps to
                                    consider per track 

        B                       :   int, the buffer size defining the
                                    maximum number of components active at
                                    any given time

        metropolis_sigma        :   float, the standard deviation of steps
                                    in log diffusivity for the parameter
                                    update step

        num_workers             :   int, the number of threads to use. Each
                                    thread runs an independent replicate.

        max_occ_weight          :   int, the maximum number of displacements 
                                    to use for weighting the current occupation
                                    of any given component.

        loc_error               :   float, the 1D localization error in um

        dz                      :   float, the depth of field in um. If *np.inf*
                                    or *None*, then the microscope is assumed
                                    to gather trajectories without any 
                                    defocalization bias.

    returns
    -------
        1D ndarray of shape (n_bins,), the integrated density of Markov
            chains on each bin of *diffusivity_bin_edgse*. This is not
            normalized.

    """
    # Check that the gs_dp_diff executable exists
    if (not os.path.isfile("gs_dp_diff")) and \
        (os.access("gs_dp_diff", os.X_OK)):
        raise RuntimeError("gs_dp_log_diff_par: must have a compiled " \
            "version of gs_dp_diff in PATH")

    # The minimum and maximum log (diffusivity) to consider
    min_log_D = np.log(diffusivity_bin_edges.min())
    max_log_D = np.log(diffusivity_bin_edges.max())
    n_bins = diffusivity_bin_edges.shape[0] - 1


    ## PREPROCESSING

    # Calculate the maximum trajectory length present among
    # these trajectories
    tracks = track_length(tracks)
    n_frames = min(tracks["track_length"].max(), max_jumps_per_track+1)

    # Calculate the 2D radial squared displacements corresponding to every
    # jump in the dataset
    vecs, n_tracks = rad_disp_squared(tracks, start_frame=0,
        n_frames=n_frames, pixel_size_um=pixel_size_um, 
        min_track_length=min_jumps_per_track+1)
    vecs = pd.DataFrame(
        vecs,
        columns=[
            "track_length", "track_index_diff",
            "dy", "dx", "squared_disp", "trajectory"
        ]
    )

    # Calculate the sum of squared displacements for each trajectory
    track_data = pd.DataFrame(index=range(n_tracks),
        columns=["sum_squared_disp", "trajectory", "track_length"])
    track_data["sum_squared_disp"] = np.asarray(
        vecs.groupby("trajectory")["squared_disp"].sum()
    )
    track_data["track_length"] = np.asarray(
        vecs.groupby("trajectory")["track_length"].first()
    )
    track_data["trajectory"] = np.asarray(
        vecs.groupby("trajectory").apply(lambda i: i.name)
    )
    track_data["n_disps"] = track_data["track_length"] - 1
    del vecs 

    # Save the sum of squared displacements and the displacement number
    # for each trajectory to a CSV
    track_csv = "_TEMP.csv"
    track_data["n_disps"] = track_data["n_disps"].astype(np.int64)
    track_data[["sum_squared_disp", "n_disps"]].to_csv(
        track_csv, index=False, header=None)


    ## FORMAT CALLS TO THE GIBBS SAMPLER

    commands = []
    for i in range(num_workers):
        commands.append(format_cl_args(
            track_csv,
            "_TEMP_OUT_{}.csv".format(i),
            verbose=(i==0),
            alpha=alpha,
            frame_interval=frame_interval,
            m=m,
            metropolis_sigma=metropolis_sigma,
            B=B,
            n_iter=n_iter,
            burnin=burnin,
            min_log_D=min_log_D,
            max_log_D=max_log_D,
            seed=int((time.perf_counter()+i)*1777)%373,
            max_occ_weight=max_occ_weight,
            loc_error=loc_error
        ))


    ## RUN GIBBS SAMPLING

    # Runs Gibbs sampling independently for each thread
    @dask.delayed
    def gb(i):

        # Execute Gibbs sampling with gs_dp_diff
        os.system(commands[i])

        # Read the output and discretize the posterior density of
        # Markov chains into a histogram
        df = pd.read_csv("_TEMP_OUT_{}.csv".format(i), header=None)
        df["D"] = (np.exp(df[0]) - 4 * (loc_error**2)) / (4 * frame_interval)
        H = np.histogram(df["D"], bins=diffusivity_bin_edges,
            weights=df[1])[0].astype(np.float64)

        return H 

    # Manage threads with dask
    scheduler = "processes" if num_workers > 1 else "single-threaded"
    jobs = [gb(i) for i in range(num_workers)]
    results = dask.compute(
        *jobs,
        scheduler=scheduler,
        num_workers=num_workers
    )

    # Aggregate results
    record = np.asarray(results).sum(axis=0)

    # Correct for defocalization biases
    Ds = np.sqrt(diffusivity_bin_edges[1:] * diffusivity_bin_edges[:-1])
    plt.plot(Ds, record, color='k'); plt.xscale('log'); plt.show(); plt.close()
    if (not dz is None) and (not dz is np.inf):
        f_remain = np.zeros(n_bins, dtype=np.float64)
        Ds = np.sqrt(diffusivity_bin_edges[1:] * diffusivity_bin_edges[:-1])
        for i, D in enumerate(Ds):
            f_remain[i] = defoc_prob_brownian(D, min_jumps_per_track,
                frame_interval, dz, n_gaps=0)[-1]
        nonzero = record > 0
        record[nonzero] = record[nonzero] / f_remain[nonzero]
    plt.plot(Ds, record, color='k'); plt.xscale('log'); plt.show(); plt.close()

    # Clean up
    if os.path.isfile(track_csv):
        os.remove(track_csv)
    for i in range(num_workers):
        fn = "_TEMP_OUT_{}.csv".format(i)
        if os.path.isfile(fn):
            os.remove(fn)

    # Return the posterior sum of Markov chain densities across
    # all threads
    return record

def format_cl_args(in_csv, out_csv, verbose=False, **kwargs):
    """
    Format a set of arguments for a call to gs_dp_diff. This essentially
    translates the keyword arguments from a call to gs_dp_log_diff_par
    to a command-line call to gs_dp_diff.

    args
    ----
        in_csv          :   str, path to a CSV with the summed squared 
                            displacements and the number of displacements
                            for each trajectory
        out_csv         :   str, path to the output CSV
        verbose         :   str, use the verbose option
        kwargs          :   keyword arguments passed to gs_dp_log_diff_par
                            relevant to the gs_dp_diff call

    returns
    -------
        str, a command line call to gs_dp_diff

    """
    keymap = {
        "alpha": "a",
        "frame_interval": "t",
        "m": "m",
        "metropolis_sigma": "s",
        "B": "z",
        "n_iter": "n",
        "burnin": "b",
        "min_log_D": "c",
        "max_log_D": "d",
        "seed": "e",
        "max_occ_weight": "x",
        "loc_error": "l"
    }
    optstr = " ".join(["-{} {}".format(str(keymap.get(k)), str(kwargs.get(k))) \
        for k in kwargs.keys() if k in keymap.keys()])
    if verbose:
        return "gs_dp_diff {} -v {} {}".format(optstr, in_csv, out_csv)
    else:
        return "gs_dp_diff {} {} {}".format(optstr, in_csv, out_csv)

